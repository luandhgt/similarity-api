# Quick Start - Multi-LLM Provider

H∆∞·ªõng d·∫´n nhanh ƒë·ªÉ chuy·ªÉn ƒë·ªïi gi·ªØa Claude, ChatGPT, Gemini trong 3 b∆∞·ªõc ƒë∆°n gi·∫£n.

---

## üöÄ C√°ch s·ª≠ d·ª•ng (3 b∆∞·ªõc)

### B∆∞·ªõc 1: C√†i ƒë·∫∑t dependencies

```bash
pip install openai>=2.0.0
```

### B∆∞·ªõc 2: C·∫•u h√¨nh API Keys trong `.env`

```bash
# Ch·ªçn provider: "claude", "chatgpt", ho·∫∑c "gemini"
LLM_PROVIDER=claude

# API Keys (ch·ªâ c·∫ßn provider b·∫°n d√πng)
CLAUDE_API_KEY=sk-ant-api03-xxxxx
OPENAI_API_KEY=sk-proj-xxxxx
GEMINI_API_KEY=your-gemini-key
```

### B∆∞·ªõc 3: Kh·ªüi ƒë·ªông l·∫°i server

```bash
uvicorn main:app --reload
```

**Xong! üéâ** H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông s·ª≠ d·ª•ng provider b·∫°n ƒë√£ ch·ªçn.

---

## üîÑ Chuy·ªÉn ƒë·ªïi Provider

### Trong file `.env`:

```bash
# S·ª≠ d·ª•ng Claude (ch√≠nh x√°c, context l·ªõn)
LLM_PROVIDER=claude

# S·ª≠ d·ª•ng ChatGPT (nhanh, r·∫ª h∆°n)
LLM_PROVIDER=chatgpt

# S·ª≠ d·ª•ng Gemini (coming soon)
LLM_PROVIDER=gemini
```

### Ho·∫∑c khi ch·∫°y:

```bash
# Development v·ªõi ChatGPT (r·∫ª h∆°n)
LLM_PROVIDER=chatgpt uvicorn main:app --reload

# Production v·ªõi Claude (ch·∫•t l∆∞·ª£ng cao)
LLM_PROVIDER=claude uvicorn main:app --workers 4
```

---

## ‚öôÔ∏è Configuration m·∫´u

### Development (ChatGPT - ti·∫øt ki·ªám chi ph√≠)

```bash
# .env.development
LLM_PROVIDER=chatgpt
OPENAI_API_KEY=sk-proj-xxxxx
OPENAI_MODEL=gpt-4o
OPENAI_MAX_TOKENS=16384
```

### Production (Claude - ch·∫•t l∆∞·ª£ng cao)

```bash
# .env.production
LLM_PROVIDER=claude
CLAUDE_API_KEY=sk-ant-xxxxx
CLAUDE_MODEL=claude-sonnet-4-5-20250929
CLAUDE_MAX_TOKENS=8000
```

---

## üìù Code Example

**Kh√¥ng c·∫ßn thay ƒë·ªïi code!** Provider ƒë∆∞·ª£c t·ª± ƒë·ªông inject:

```python
from core.container import get_container, ServiceNames

# Get current provider (t·ª± ƒë·ªông theo config)
container = get_container()
llm = container.get(ServiceNames.CLAUDE)

# S·ª≠ d·ª•ng nh∆∞ b√¨nh th∆∞·ªùng
response = await llm.generate_text("Hello AI!")

# Ph√¢n t√≠ch ·∫£nh
result = await llm.analyze_image(
    image_path="screenshot.jpg",
    prompt="Extract text from this image"
)

# T·ªïng h·ª£p nhi·ªÅu ·∫£nh + text
summary = await llm.synthesize_with_images_and_texts(
    image_paths=["img1.jpg", "img2.jpg"],
    texts=["OCR 1", "OCR 2"],
    user_prompt="Create summary"
)
```

---

## ‚úÖ Ki·ªÉm tra Provider ƒëang d√πng

```bash
# Check trong logs
tail -f logs/image-similarity-api.log

# Ho·∫∑c check programmatically
python -c "from config import Config; print(Config.LLM_PROVIDER)"
```

---

## üéØ Khi n√†o d√πng Provider n√†o?

| Use Case | Recommended Provider | L√Ω do |
|----------|---------------------|-------|
| **Development/Testing** | ChatGPT | R·∫ª h∆°n, nhanh h∆°n |
| **Production (High Quality)** | Claude | Ch√≠nh x√°c h∆°n, context l·ªõn |
| **High Throughput** | ChatGPT | Rate limits tho√°ng h∆°n |
| **Ti·∫øng Vi·ªát** | Claude | H·ªó tr·ª£ t·ªët h∆°n |
| **Budget Limited** | ChatGPT | Chi ph√≠ th·∫•p h∆°n |

---

## üîß Troubleshooting

### L·ªói: API key kh√¥ng h·ª£p l·ªá

```bash
# Ki·ªÉm tra API key
echo $CLAUDE_API_KEY
echo $OPENAI_API_KEY

# Test API key
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
     https://api.openai.com/v1/models
```

### L·ªói: Model kh√¥ng support vision

**Solution:** D√πng models c√≥ vision:
- Claude: T·∫•t c·∫£ Claude 3+ models
- OpenAI: `gpt-4o`, `gpt-4-vision-preview`, `gpt-4-turbo`

---

## üìö ƒê·ªçc th√™m

- [Full Documentation](./MULTI_LLM_PROVIDER.md) - Chi ti·∫øt ƒë·∫ßy ƒë·ªß
- [API Reference](./MULTI_LLM_PROVIDER.md#api-reference) - T·∫•t c·∫£ methods
- [Architecture](./MULTI_LLM_PROVIDER.md#architecture) - Thi·∫øt k·∫ø h·ªá th·ªëng

---

## üí° Tips

1. **Development**: D√πng ChatGPT ƒë·ªÉ ti·∫øt ki·ªám chi ph√≠
2. **Production**: D√πng Claude cho ch·∫•t l∆∞·ª£ng cao
3. **Monitor logs**: ƒê·ªÉ track provider n√†o ƒëang ƒë∆∞·ª£c d√πng
4. **Test c·∫£ 2**: So s√°nh k·∫øt qu·∫£ ƒë·ªÉ ch·ªçn provider ph√π h·ª£p

---

ƒê√£ xong! B·∫°n c√≥ th·ªÉ d·ªÖ d√†ng chuy·ªÉn ƒë·ªïi gi·ªØa c√°c AI provider ch·ªâ b·∫±ng 1 d√≤ng config. üéâ
